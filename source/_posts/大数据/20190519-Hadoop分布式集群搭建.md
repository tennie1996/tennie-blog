---
title: Hadoop分布式集群的搭建
summary: 关键词：Hadoop分布式集群的搭建 Hadoop ubuntu 分布式集群 环境搭建 ssh 网络配置 java环境 
date: 2019-5-19 11:09
author: foochane
urlname: 2019051901
categories: 大数据
tags:
  - hadoop
  - 大数据
top: false
cover: true
---

>Hadoop分布式集群的搭建 Hadoop ubuntu 分布式集群 环境搭建 ssh 网络配置 java环境 



## 1 安装说明

### 1.1 用到的软件
|软件|版本|下载地址|
|--|--|--|
|linux|Ubuntu Server 18.04.2 LTS|https://www.ubuntu.com/download/server|
|hadoop|hadoop-2.7.1|http://archive.apache.org/dist/hadoop/common/hadoop-2.7.1/hadoop-2.7.1.tar.gz|
|java|jdk-8u211-linux-x64|https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html|

### 1.2 节点安排
|名称|ip|hostname|
|-|-|-|
|主节点|192.168.233.200|Master|
|子节点1|192.168.233.201|Slave01|
|子节点2|192.168.233.202|Slave02|

## 2 创建hadoop用户
所有的节点均创建一个名为`hadoop`的用户，并添加管理员权限。
**注意：这里这是单纯为了方便管理，创建的用户名，也可以使用其他用户名，或者使用系统之前的用户，主要有管理员权限即可**

```bash
$ sudo useradd -m hadoop -s /bin/bash #创建用户
$ sudo passwd hadoop #修改密码
$ sudo adduser hadoop sudo #添加管理员权限
```

## 3 配置网络环境

### 3.1 修改主机名
修改 `/etc/hostname`文件，每个节点都要修改。
- 主节点修改为：Master
- 从节点分别修改为：Slave01,Slave02,...

**注意：如果是ubuntu18.04桌面版直接修改`/etc/hostname`文件即可，ubuntu18.04服务器版还需要修改`/etc/cloud/cloud.cfg`文件**，修改如下：
```bash
# This will cause the set+update hostname module to not operate (if true)
preserve_hostname: true  #这里是将false改成true
```

### 3.2 添加IP与主机名的映射关系
在`/etc/hosts`文件里添加如下内容（每个节点都要修改，根据实际情况修改ip)

```bash
192.168.233.200  Master
192.168.233.201  Slave01
192.168.233.202  Slave02
```

检查各个节点是否能相互ping通。


### 3.3 设置SSH无密码登录节点
让Master能够通过SSH无密码登录各个Slave节点

如果修改过主机名，需要重新生成的新的公钥。

在Master上执行如下命令：
```bash
$ cd ~/.ssh              # 如果没有该目录，先执行一次ssh localhost
$ rm ./id_rsa*           # 删除之前生成的公匙（如果已经存在）
$ ssh-keygen -t rsa       # 执行该命令后，遇到提示信息，一直按回车就可以
$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
```

接着将Master中的id_rsa.pub文件复制到各个Slave节点中

```bash
$ scp ~/.ssh/id_rsa.pub hadoop@Slave01:/home/hadoop/
$ scp ~/.ssh/id_rsa.pub hadoop@Slave02:/home/hadoop/
```

在各个Slave节点中执行如下命令：
```bash
$ mkdir ~/.ssh       # 如果不存在该文件夹需先创建
$ cat ~/id_rsa.pub >> ~/.ssh/authorized_keys
$ rm ~/id_rsa.pub    # 用完以后就可以删掉
```

在Master中验证是否可以无密码登录，各个Slave节点。

如：
```bash
$ ssh Slave01 #如果成功登录，则配置完成
$ ssh Slave02 #如果成功登录，则配置完成
```

## 4 安装java环境
**每个节点都要安装，步骤相同**
为了方便操作每个节点，默认在`/usr/local/`下新建一个名为`bigdata`的文件夹，存放所有的大数据相关的软件。
```
$ sudo mkdir /usr/local/bigdata
$ sudo chown -R hadoop:hadoop /usr/local/bigdata/
```

### 4.1 解压
```bash
$ sudo mkdir /usr/local/bigdata/java
$ sudo tar -zxvf jdk-8u211-linux-x64.tar.gz -C /usr/local/bigdata/java/

```

### 4.2 添加环境变量

在`~/.bashrc`文件中添加如下内容，并执行`$ source ~/.bashrc`命令使其生效

```bash
#java
export JAVA_HOME=/usr/local/bigdata/java/jdk1.8.0_211
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH

```


## 5 解压hadoop
下载`hadoop-2.7.1.tar.gz`文件，并解压到`/usr/local/bigdata/`文件夹下

```bash
$ sudo tar -zxvf hadoop-2.7.1.tar.gz -C /usr/local/bigdata

```

## 6 修改hadoop配置文件
需要修改6个文件，文件位于`/usr/local/bigdata/hadoop-2.7.1/etc/hadoop/`下

### 6.1 slave 文件
将文件中原来的 `localhost` 删除，添加内容：
```
Slave01
Slave02
```

### 6.2 core-site.xml 文件
内容修改为：

```xml
<configuration>
        <!-- 指定HADOOP所使用的文件系统schema（URI）-->
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://Master:9000</value>
        </property>

         <!-- 指定hadoop运行时产生文件的存储目录 -->
        <property>
                <name>hadoop.tmp.dir</name>
                <value>file:/usr/local/bigdata/hadoop-2.7.1/tmp</value>
                <description>Abase for other temporary directories.</description>
        </property>
</configuration>
```

### 6.3 hdfs-site.xml文件

Hadoop的分布式文件系统HDFS一般采用冗余存储，一份文件通常保存3份副本，所以dfs.replication的值还是设置为3。
具体内容如下：
```xml
<configuration>
        <property>
                <!-- 指定SecondaryNamenode所在地址 -->
                <name>dfs.namenode.secondary.http-address</name>
                <value>Master:50090</value>
        </property>
        <property>
                <name>dfs.replication</name>
                <value>3</value>
        </property>
        <property>
                <name>dfs.namenode.name.dir</name>
                <value>file:/usr/local/bigdata/hadoop-2.7.1/tmp/dfs/name</value>
        </property>
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>file:/usr/local/bigdata/hadoop-2.7.1/tmp/dfs/data</value>
        </property>
</configuration>
```

### 6.4 mapred-site.xml 文件
修改内容如下：

```xml
<configuration>
        <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
        </property>
        <property>
                <name>mapreduce.jobhistory.address</name>
                <value>Master:10020</value>
        </property>
        <property>
                <name>mapreduce.jobhistory.webapp.address</name>
                <value>Master:19888</value>
        </property>
</configuration>
```

### 6.5 yarn-site.xml文件
内容如下：

```xml
<configuration>
        <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>Master</value>
        </property>
        <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
        </property>
</configuration>
```

### 6.6 hadoop-env.sh 文件

修改如下内容：
```bash
export JAVA_HOME=/usr/local/bigdata/java/jdk1.8.0_211

# 可以不用
export HADOOP_HOME=/usr/local/hadoop-2.7.1
```

## 7 设置hadoop环境变量
每个节点都要设置
在`~/.bashrc`文件中添加如下内容，并`$ source ~/.bashrc`使其生效
```
export PATH=$PATH:/usr/local/bigdata/hadoop-2.7.1/bin:/usr/local/bigdata/hadoop-2.7.1/sbin
```
## 8 slave节点配置
slave节点只需将master节点上`/usr/local/`下的`bigdata`文件夹和`~/.bashrc`文件，放到slave节点即可
注意切换到对应机器执行`$ source ~/.bashrc`使环境变量生效。

后续的软件均可使用此方式配置。

在master节点：
```bash
$ sudo rm -r /usr/local/bigdata/hadoop-2.7.1/tmp     # 删除 Hadoop 临时文件，如果之前有启动过
$ sudo rm -r /usr/local/bigdata/hadoop-2.7.1/logs/*   # 删除日志文件，如果之前有启动过
$ tar -zcvf ~/bigdata.tar.gz /usr/local/bigdata/ # 先压缩再复制
$ scp ~/bigdata.tar.gz Slave01:/home/hadoop
$ scp ~/bigdata.tar.gz Slave02:/home/hadoop
$ scp ~/bashrc Slave01:/home/hadoop
$ scp ~/bashrc Slave02:/home/hadoop
```


在各个slave节点上
```bash
$ sudo mkdir /usr/local/bigdata
$ sudo chown -R hadoop：hadoop /usr/local/bigdata
$ tar -zxvf ~/bigdata.tar.gz -C /usr/local/bigdata
$ sudo source ~/.bashrc
```

## 9 启动Hadoop集群
**在Master上执行**
首次运行需要，执行
```bash
$ hdfs namenode -format 

```

格式化名称节点，然后就可以启动hadoop了。

启动hadoop：
```bash
$ start-dfs.sh
$ start-yarn.sh
$ mr-jobhistory-daemon.sh start historyserver
```

使用jps查看启动的各个节点，缺少任何进程，都表示出错。
```bash
$ jps
3585 JobHistoryServer
2938 NameNode
3148 SecondaryNameNode
3308 ResourceManager
3629 Jps
```

浏览器查看：http://192.168.233.200:50070/

查看相关信息：`$ hdfs dfsadmin -report`


关闭hadoop：
```bash
$ stop-yarn.sh
$ stop-dfs.sh
$ mr-jobhistory-daemon.sh stop historyserver
```

如果有问题，重复如下命令：
```bash
$ stop-dfs.sh   # 关闭
$ rm -r /usr/local/bigdata/hadoop-2.7.1/tmp     # 删除 tmp 文件，注意这会删除 HDFS中原有的所有数据
$ hdfs namenode -format   # 重新格式化名称节点
$ start-dfs.sh  # 重启
```


<!-- >本文作者：[foochane](https://foochane.cn/) 
本文链接：[https://foochane.cn/article/2019051901.html](https://foochane.cn/article/2019051901.html) -->

